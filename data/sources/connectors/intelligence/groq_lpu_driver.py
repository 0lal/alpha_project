import logging
from typing import Dict, Any, Optional, List, Tuple
import json

# ุงุณุชูุฑุงุฏ ุงููุงูุจ ุงูุฃู ุงูุฐู ูุญุชูู ุนูู ุฌุฏุงุฑ ุงูุญูุงูุฉ (Firewall) ูุณูุงุณุงุช ุงูุงุชุตุงู
from connectors.base_connector import BaseConnector

# ุฅุนุฏุงุฏ ุงูุณุฌู ุงูุฌูุงุฆู ุงูุฎุงุต ุจู Groq LPU
logger = logging.getLogger("Alpha.Drivers.GroqLPU")

class GroqLPUDriver(BaseConnector):
    """
    ุงูุฐุฑุงุน ุงูุชูููุฐู ููุฐูุงุก ุงูุงุตุทูุงุนู ูุงุฆู ุงูุณุฑุนุฉ (Groq LPU).
    
    ุงูููุงู ุงูุฌูุงุฆูุฉ:
    1. ุชูููุฑ ุชุญููู ูุงูู ูุญุธู ุจุงุณุชุฎุฏุงู ููุงุฐุฌ Llama3.
    2. ูุนุงูุฌุฉ ุงููุตูุต ูุญูุงูุฉ ุงููุธุงู ูู ุชุฌุงูุฒ ุณูู ุงูู 8192 ุชููู.
    3. ูุจุญ ุงููููุณุฉ (Zero-Hallucination Policy) ูู ุงูุชูุงุฑูุฑ ุงููุงููุฉ.
    4. ุงูุนูู ูุจุฏูู (Fallback) ููู ุฅุฐุง ูุดู ูููุฐุฌ Gemini ูู ุงุชุฎุงุฐ ุงููุฑุงุฑ.
    """

    # ุงูุญุฏ ุงูุฃูุตู ุงูุชูุฑูุจู ูุนุฏุฏ ุงูุฃุญุฑู ุงููุณููุญ ุฅุฑุณุงูู ูููุน ุฎุทุฃ 413 (Payload Too Large)
    # (8192 ุชููู ุชุณุงูู ุชูุฑูุจุงู 30,000 ุญุฑู ุจุงููุบุฉ ุงูุฅูุฌููุฒูุฉ)
    MAX_PAYLOAD_CHARS = 28000 

    def __init__(self):
        """
        ุชููุฆุฉ ุงูุฏุฑุงููุฑ.
        """
        # ุชูุฑูุฑ ุงุณู ุงููุฒูุฏ ูููุงูุจ ุงูุฃู ูุฌูุจ ุงูุฅุนุฏุงุฏุงุช ูู ููู JSON ุงูุฎุงุต ุจู
        super().__init__("groq")
        
        # ุงุณุชุฎุฑุงุฌ ุงูููุชุงุญ ูู ูููุงุช ุงูุชูููู ุงูุขููุฉ
        self.api_key = self.config.get("credentials", {}).get("api_key")
        
        if not self.api_key:
            logger.critical("โ FATAL: Groq API Key is missing from secure configuration!")

    def build_url(self, endpoint_key: str) -> str:
        """
        ุจูุงุก ุงูุฑุงุจุท.
        Groq ูุณุชุฎุฏู ูุงุฌูุฉ ูุชูุงููุฉ ูุน OpenAI.
        """
        base_url = self.config.get("connection_policy", {}).get("base_url", "https://api.groq.com/openai/v1")
        
        endpoints = {
            "chat_completions": "/chat/completions",
            "models": "/models"
        }
        
        path = endpoints.get(endpoint_key, "/chat/completions")
        return f"{base_url}{path}"

    def get_default_params(self) -> Dict[str, Any]:
        """
        Groq ูุชุทูุจ ุฅุฑุณุงู ุงูุจูุงูุงุช ูู JSON Bodyุ ูุฐุง ูุชุฑู ุงูู Query Params ูุงุฑุบุฉ.
        """
        return {}

    def _prepare_request_details(self, endpoint_key: str, params: Dict) -> Tuple[str, str, Dict, Dict]:
        """
        [ุชุฌุงูุฒ ุฃููู - Security Override]
        ุญูู ููุชุงุญ ุงููุตูู ูู ุงูุชุฑููุณุฉ (Header) ุจุตูุบุฉ Bearer Token.
        ูุชุญุฏูุฏ ุทุฑููุฉ ุงูุงุชุตุงู ูู POST.
        """
        url, method, final_params, headers = super()._prepare_request_details(endpoint_key, params)
        
        # ุญูู ุงููุตุงุฏูุฉ ุงูููุงุณูุฉ ุงููุดูุฑุฉ
        headers["Authorization"] = f"Bearer {self.api_key}"
        headers["Content-Type"] = "application/json"
        
        # ูุงุฌูุฉ ุงููุญุงุฏุซุฉ ุชุชุทูุจ ุฅุฑุณุงู POST ุฏุงุฆูุงู
        return url, "POST", final_params, headers

    def fetch(self, endpoint_key: str, **params) -> Optional[str]:
        """
        [ุชุฌุงูุฒ ุฌูุงุฆู - Extraction Override]
        ูุฐู ุงูุฏุงูุฉ ุชุฑุณู ุงูุทูุจ ูุชุณุชุฎุฑุฌ "ุงููุต ุงููุนูู" ูู ูููู JSON ุงููุนูุฏ.
        ุฃู ูุดู ููุง ูุนูุฏ Noneุ ููุง ูุนูู "ุงููุธุงู ุฃุนูู ููุง ููุฌุฏ ุจูุงูุงุช ุงูุชุฑุงุถูุฉ".
        """
        # 1. ุงูุฅุฑุณุงู ุนุจุฑ ุฌุฏุงุฑ ุงูุญูุงูุฉ ูู ุงููุงูุจ ุงูุฃู
        result = super().fetch(endpoint_key, **params)
        
        # 2. ุงููุญุต ุงูุฌูุงุฆู ููุชูุฌุฉ ุงูุฑุฏ
        if not result or not isinstance(result, dict):
            return None

        # 3. ุงุณุชุฎุฑุงุฌ ุงููุญุชูู (Content) ูู ุงูุฑุฏ
        try:
            choices = result.get("choices", [])
            if not choices:
                logger.error("๐ Groq API Error: No 'choices' returned in response.")
                return None
                
            content = choices[0].get("message", {}).get("content")
            
            if not content:
                logger.error("๐ Groq API Error: Empty content received.")
                return None
                
            return content.strip()

        except Exception as e:
            logger.error(f"๐ Groq JSON Parsing Error: {str(e)}")
            if hasattr(self, 'audit_logger') and self.audit_logger:
                self.audit_logger.log_error("GROQ_PARSE_ERROR", "Failed to extract AI content", str(e))
            return None

    # =========================================================================
    # ุฃุฐุฑุน ุงูุชุญููู ุงูุฐูู (Intelligence Arms)
    # =========================================================================

    def _trim_payload(self, text: str) -> str:
        """
        [ูุงุทุน ุงูุชูุงุฑ - Circuit Breaker]
        ุญูุงูุฉ ุงููุธุงู ูู ุงูุงูููุงุฑ ุฅุฐุง ูุงู ุงููุต ุฃุทูู ูู ูุฏุฑุฉ ุงุณุชูุนุงุจ Groq (8192 ุชููู).
        ูููู ุจูุต ุงููุต ูู ุงูููุชุตู ููุญุชูุธ ุจุฃูู ุงูุฃุฌุฒุงุก (ุงูุจุฏุงูุฉ ูุงูููุงูุฉ).
        """
        if len(text) <= self.MAX_PAYLOAD_CHARS:
            return text
            
        logger.warning(f"โ๏ธ Payload too large ({len(text)} chars). Trimming to prevent Groq API crash.")
        
        half_limit = (self.MAX_PAYLOAD_CHARS // 2) - 500
        # ูุญุชูุธ ุจุงูุจุฏุงูุฉ ูุงูููุงูุฉ ููุถุน ุนูุงูุฉ ูู ุงูููุชุตู
        trimmed_text = text[:half_limit] + "\n\n... [SYSTEM TRUNCATED MIDDLE CONTENT DUE TO MEMORY LIMITS] ...\n\n" + text[-half_limit:]
        return trimmed_text

    def generate_financial_report(self, system_prompt: str, market_data: str) -> Optional[str]:
        """
        ุฅูุดุงุก ุชูุฑูุฑ ูุงูู ูุนูุฏ ูุงุชุฎุงุฐ ูุฑุงุฑุงุช ูุตูุฑูุฉ.
        ูุณุชุฎุฏู ุงููููุฐุฌ ุงูุฃุฐูู ูุงูุฃุซูู (Llama 3 70B).
        """
        # ุญูุงูุฉ ุงููุต ูู ุชุฌุงูุฒ ุงูุญุฏ ุงููุณููุญ
        safe_data = self._trim_payload(market_data)

        # ุชุฌููุฒ ูููู ุงููุญุงุฏุซุฉ ุงูููุงุณู (OpenAI/Groq Format)
        payload = {
            "model": "llama3-70b-8192", # ุงููููุฐุฌ ุงููุฎุตุต ููููุงู ุงูุซูููุฉ ูุงููุฑุงุฑุงุช
            "messages": [
                {
                    "role": "system",
                    "content": f"You are a strict financial AI. Base your answers ONLY on the provided data. Do not guess, do not hallucinate. If data is insufficient, state: 'INSUFFICIENT_DATA'.\n{system_prompt}"
                },
                {
                    "role": "user",
                    "content": safe_data
                }
            ],
            "temperature": 0.1, # ุญุฑุงุฑุฉ ุดุจู ุตูุฑูุฉ ูููุน ุงูุชุฒููู ูุงููููุณุฉ
            "max_tokens": 4000,
            "top_p": 0.9
        }
        
        logger.info("๐ง Requesting Deep Financial Analysis via Groq (llama3-70b)")
        return self.fetch("chat_completions", **payload)

    def quick_data_extraction(self, text_to_parse: str, extraction_goal: str) -> Optional[str]:
        """
        ุงุณุชุฎุฑุงุฌ ุณุฑูุน ููุจูุงูุงุช (ูุซุงู: ูุฑุงุกุฉ ุฎุจุฑ ูุงุณุชุฎุฑุงุฌ ุงุณู ุงูุณูู ููู).
        ูุณุชุฎุฏู ุงููููุฐุฌ ุงูุฃุณุฑุน ูุงูุฃุฎู (Llama 3 8B).
        """
        safe_text = self._trim_payload(text_to_parse)

        payload = {
            "model": "llama3-8b-8192", # ุงููููุฐุฌ ุงููุฎุตุต ููุณุฑุนุฉ ูุงูููุงู ุงูุจุณูุทุฉ
            "messages": [
                {
                    "role": "system",
                    "content": f"Extract the following information exactly as requested. No extra words, no pleasantries.\nGoal: {extraction_goal}"
                },
                {
                    "role": "user",
                    "content": safe_text
                }
            ],
            "temperature": 0.0, # ุตูุฑ ุชูุงูุงู ููุงุณุชุฎุฑุงุฌ ุงูุญุฑูู (Exact Match)
            "max_tokens": 500
        }
        
        logger.info("โก Requesting Quick Data Extraction via Groq (llama3-8b)")
        return self.fetch("chat_completions", **payload)